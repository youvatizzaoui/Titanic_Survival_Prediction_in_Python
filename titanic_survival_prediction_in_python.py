# -*- coding: utf-8 -*-
"""Titanic_Survival_Prediction_in_Python.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xws4FkGryvFjyQbzQdkeuUxNivxA1YYb
"""

import numpy as np 
import pandas as pd
import matplotlib.pyplot as plt

titanic_data = pd.read_csv('train.csv')

titanic_data.shape

titanic_data.head()

titanic_data.info()

titanic_data

index_with_nan = titanic_data.index[titanic_data.isnull().any(axis=1)]
print(index_with_nan)

titanic_data



titanic_data.describe()

import seaborn as sns 
sns.heatmap(titanic_data.corr(), cmap='YlGnBu')
plt.show()

sns.pairplot(titanic_data)

index_with_nan = titanic_data.index[titanic_data.isnull().any(axis=1)]
print(index_with_nan)

titanic_data.drop(index_with_nan,0, inplace=True)
titanic_data

titanic_data.fillna(0)
titanic_data = titanic_data.drop(columns=['Ticket'],axis = 1)
titanic_data =titanic_data.replace("S", 1)
titanic_data  =titanic_data.replace("C", 2)
titanic_data  =titanic_data.replace("Q", 3)
titanic_data = titanic_data.drop(columns=['Name'],axis = 1)
titanic_data = titanic_data.drop(columns=['Cabin'],axis = 1)
titanic_data = titanic_data = titanic_data.replace("male", 1)
titanic_data = titanic_data = titanic_data.replace("female", 2)
titanic_data.dropna(how = 'any')
target = titanic_data ['Survived']
titanic_data = titanic_data.drop(columns=['Survived'],axis = 1)

print(titanic_data,target)

from sklearn.model_selection import train_test_split 
X_train,  X_test,  y_train,  y_test  =  train_test_split(titanic_data,  target,  train_size=0.75, random_state=0)

from sklearn.preprocessing import StandardScaler , MinMaxScaler
import time
from sklearn.neural_network import MLPClassifier
scaler = MinMaxScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)
start_time=time.time()
clf = MLPClassifier(hidden_layer_sizes=(100,1000,9),activation = 'relu',solver='lbfgs',random_state=0,max_iter=500).fit(X_train, y_train)
clf.score(X_test, y_test)
pred = clf.predict(X_test)
print ("le score est de "+str(clf.score(X_test, y_test) ))
end_time = time.time()
print('temps ecoule = '+str(end_time - start_time))

from sklearn.model_selection import GridSearchCV

parameters={'hidden_layer_sizes':[100,(20,50),(10,20,50),(50,20,10),(50,100,200,300)],
            'activation':['identity', 'logistic', 'relu', 'softmax', 'tanh' ],
            'solver': ['lbfgs','sgd','adam'],
            'alpha':[0.1,0.01,0.001,0.00001],
            'learning_rate':['constant','invscaling','adaptive']}
tree=MLPClassifier()
grid=GridSearchCV(tree,parameters) 
grid.fit(X_train,y_train)

from sklearn.metrics import classification_report, confusion_matrix 

grid_predictions = clf.predict(X_test) 
print(classification_report(y_test, grid_predictions)) 
print(grid.best_params_)

from sklearn.preprocessing import StandardScaler , MinMaxScaler
import time
from sklearn.neural_network import MLPClassifier
scaler = MinMaxScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)
start_time=time.time()
clf = MLPClassifier(hidden_layer_sizes=(50, 100, 200, 300),solver='sgd',activation='identity',learning_rate= 'constant' ,alpha= 0.001,random_state=0).fit(X_train, y_train)
clf.score(X_test, y_test)
pred = clf.predict(X_test)
print ("le score est de: {:.2f} ".format(clf.score(X_test, y_test) ))
end_time = time.time()
print('temps ecoule = {:.2f} s'.format(end_time - start_time))

"""MLPClassifier"""

from sklearn.preprocessing import StandardScaler , MinMaxScaler
import time
from sklearn.neural_network import MLPClassifier
scaler = MinMaxScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)
start_time=time.time()
clf = MLPClassifier(hidden_layer_sizes=(10, 20, 50),activation = 'relu',solver='adam',learning_rate= 'adaptive',alpha= 0.001,random_state=0).fit(X_train, y_train)
clf.score(X_test, y_test)
pred = clf.predict(X_test)
print ("le score est de: {:.2f} ".format(clf.score(X_test, y_test) ))
end_time = time.time()
print('temps ecoule = {:.2f} s'.format(end_time - start_time))

"""RandomForestClassifier"""

from sklearn.preprocessing import StandardScaler , MinMaxScaler
import time
from sklearn.ensemble import RandomForestClassifier
scaler = MinMaxScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)
start_time=time.time()
RFC = RandomForestClassifier(n_estimators=500,max_depth=9,min_samples_split=3).fit(X_train,y_train).fit(X_train, y_train)
RFC.score(X_test, y_test)
pred = RFC.predict(X_test)
print ("le score est de: {:.2f} ".format(RFC.score(X_test, y_test) ))
end_time = time.time()
print('temps ecoule = {:.2f} s'.format(end_time - start_time))

from sklearn.preprocessing import StandardScaler , MinMaxScaler
import time
from lightgbm import LGBMClassifier
scaler = MinMaxScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)
start_time=time.time()
LGB = LGBMClassifier(learning_rate=0.01,max_depth=5,n_estimators=500,num_leaves=3).fit(X_train,y_train)
LGB.score(X_test, y_test)
pred = LGB.predict(X_test)
print ("le score est de: {:.2f} ".format(LGB.score(X_test, y_test) ))
end_time = time.time()
print('temps ecoule = {:.2f} s'.format(end_time - start_time))

"""SVM Noyau polynomial """

from sklearn.preprocessing import StandardScaler , MinMaxScaler
import time
from sklearn.svm import SVC
scaler = MinMaxScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)
start_time=time.time()
svclassifier = SVC(kernel='poly', degree=8).fit(X_train,y_train)
svclassifier.score(X_test, y_test)
pred = svclassifier.predict(X_test)
print ("le score est de: {:.2f} ".format(svclassifier.score(X_test, y_test) ))
end_time = time.time()
print('temps ecoule = {:.2f} s'.format(end_time - start_time))